{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzk7iX_CodX6",
        "tags": []
      },
      "source": [
        "# **Here I have implemented collaborative filtering to build a recommender system for movies.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2q1O3Nj6KrNj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBP5R0FSKrNn",
        "tags": []
      },
      "source": [
        "## **Recommender System**\n",
        "I have implemented the collaborative filtering learning algorithm and applied it to a dataset of movie ratings.\n",
        "The goal of a collaborative filtering recommender system is to generate two vectors: For each user, a 'parameter vector' that embodies the movie tastes of a user. For each movie, a feature vector of the same size which embodies some description of the movie. The dot product of the two vectors plus the bias term should produce an estimate of the rating the user might give to that movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTJNsR0YKrNo"
      },
      "source": [
        "In this dataset, existing ratings are in matrix form. $Y$ contains ratings; 0.5 to 5 inclusive in 0.5 steps. 0 if the movie has not been rated. $R$ has a 1 where movies have been rated. Movies are in rows, users in columns. Each user has a parameter vector $w^{user}$ and bias. Each movie has a feature vector $x^{movie}$. These vectors are simultaneously learned by using the existing user/movie ratings as training data. One training example can be like: $\\mathbf{w}^{(1)} \\cdot \\mathbf{x}^{(1)} + b^{(1)} = 4$. It is worth noting that the feature vector $x^{movie}$ must satisfy all the users while the user vector $w^{user}$ must satisfy all the movies. ***Hence, this approach is known as Collaborative Filtering - all the users collaborate to generate the rating set. ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll1heNgcKrNq"
      },
      "source": [
        "Once the feature vectors and parameters are learned, they can be used to predict how a user might rate an unrated movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-09Hto6odYD"
      },
      "source": [
        "## **Movie ratings dataset**\n",
        "\n",
        "The data set is derived from the [MovieLens \"ml-latest-small\"](https://grouplens.org/datasets/movielens/latest/) dataset.\n",
        "\n",
        "This dataset consists of ratings on a scale of 0.5 to 5 in 0.5 step increments. This dataset has $n_u = 443$ users, and $n_m= 4778$ movies.\n",
        "\n",
        "Below, you will load the movie dataset into the variables $Y$ and $R$.\n",
        "\n",
        "The matrix $Y$ (a  $n_m \\times n_u$ matrix) stores the ratings $y^{(i,j)}$. The matrix $R$ is an binary-valued indicator matrix, where $R(i,j) = 1$ if user $j$ gave a rating to movie $i$, and $R(i,j)=0$ otherwise.\n",
        "\n",
        "We have matrices X, W and b as well.\n",
        "\n",
        "The $i$-th row of $\\mathbf{X}$ corresponds to the\n",
        "feature vector $x^{(i)}$ for the $i$-th movie, and the $j$-th row of\n",
        "$\\mathbf{W}$ corresponds to one parameter vector $\\mathbf{w}^{(j)}$, for the\n",
        "$j$-th user. Both $x^{(i)}$ and $\\mathbf{w}^{(j)}$ are $n$-dimensional\n",
        "vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ZMzRWYrdKrNt",
        "outputId": "41a4e2e4-50a0-4c07-9d82-54890ec222d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y (4778, 443) R (4778, 443)\n",
            "X (4778, 10)\n",
            "W (443, 10)\n",
            "b (1, 443)\n",
            "num_features 10\n",
            "num_movies 4778\n",
            "num_users 443\n"
          ]
        }
      ],
      "source": [
        "#Load data\n",
        "X, W, b, num_movies, num_features, num_users = load_precalc_params_small()\n",
        "Y, R = load_ratings_small()\n",
        "\n",
        "print(\"Y\", Y.shape, \"R\", R.shape)\n",
        "print(\"X\", X.shape)\n",
        "print(\"W\", W.shape)\n",
        "print(\"b\", b.shape)\n",
        "print(\"num_features\", num_features)\n",
        "print(\"num_movies\",   num_movies)\n",
        "print(\"num_users\",    num_users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bxm1O_wbodYF",
        "outputId": "74171570-abbc-44de-895a-408bd4f276eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average rating for movie 1 : 3.400 / 5\n"
          ]
        }
      ],
      "source": [
        "#  From the matrix, we can compute statistics like average rating.\n",
        "tsmean =  np.mean(Y[0, R[0, :].astype(bool)])\n",
        "print(f\"Average rating for movie 1 : {tsmean:0.3f} / 5\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8KloQ4PKrNx"
      },
      "source": [
        "## **Collaborative filtering learning algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcqg0LJWodYH"
      },
      "source": [
        "### **Collaborative filtering cost function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "y0mKWqTZKrNz"
      },
      "outputs": [],
      "source": [
        "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
        "    \"\"\"\n",
        "    Returns the cost for the content-based filtering\n",
        "    Args:\n",
        "      X (ndarray (num_movies,num_features)): matrix of item features\n",
        "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
        "      b (ndarray (1, num_users)            : vector of user parameters\n",
        "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
        "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
        "      lambda_ (float): regularization parameter\n",
        "    Returns:\n",
        "      J (float) : Cost\n",
        "    \"\"\"\n",
        "    nm, nu = Y.shape\n",
        "    J = 0\n",
        "\n",
        "    for i in range(nm):\n",
        "        for j in range(nu):\n",
        "            if(R[i][j] == 1):\n",
        "                J += ((np.dot(W[j], X[i]) + b[0][j]) - Y[i][j])**2\n",
        "\n",
        "    J = J/2\n",
        "    reg1 = 0\n",
        "    for j in range(nu):\n",
        "        reg1 += np.sum(W[j]**2)\n",
        "\n",
        "    reg2 = 0\n",
        "    for i in range(nm):\n",
        "        reg2 += np.sum(X[i]**2)\n",
        "\n",
        "    reg1 = (lambda_/2)*reg1\n",
        "    reg2 = (lambda_/2)*reg2\n",
        "\n",
        "    J = J + reg1 + reg2\n",
        "\n",
        "\n",
        "    return J"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0lq7DQ_XKrN0",
        "outputId": "02ea5c89-df9e-425a-8cd9-cb3c398027e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost: 13.67\n"
          ]
        }
      ],
      "source": [
        "# Reducing the data set size so that this runs faster (just to check the cost as of now)\n",
        "num_users_r = 4\n",
        "num_movies_r = 5\n",
        "num_features_r = 3\n",
        "\n",
        "X_r = X[:num_movies_r, :num_features_r]\n",
        "W_r = W[:num_users_r,  :num_features_r]\n",
        "b_r = b[0, :num_users_r].reshape(1,-1)\n",
        "Y_r = Y[:num_movies_r, :num_users_r]\n",
        "R_r = R[:num_movies_r, :num_users_r]\n",
        "\n",
        "# Evaluating cost function\n",
        "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 0);\n",
        "print(f\"Cost: {J:0.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mamLE-YRKrN1",
        "outputId": "49fd9cef-8956-4e33-8b0a-c6d8e9df7cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost (with regularization): 28.09\n"
          ]
        }
      ],
      "source": [
        "# Evaluating cost function with regularization\n",
        "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
        "print(f\"Cost (with regularization): {J:0.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-FZUtHTKrN2"
      },
      "source": [
        "**Vectorized Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1mNyNrxGKrN2"
      },
      "outputs": [],
      "source": [
        "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
        "    \"\"\"\n",
        "    Returns the cost for the content-based filtering\n",
        "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
        "    Args:\n",
        "      X (ndarray (num_movies,num_features)): matrix of item features\n",
        "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
        "      b (ndarray (1, num_users)            : vector of user parameters\n",
        "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
        "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
        "      lambda_ (float): regularization parameter\n",
        "    Returns:\n",
        "      J (float) : Cost\n",
        "    \"\"\"\n",
        "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
        "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
        "    return J"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wAqAUR59KrN3",
        "outputId": "1344b2f9-c72d-40e6-ecfc-f3c06c4e7b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost: 13.67\n",
            "Cost (with regularization): 28.09\n"
          ]
        }
      ],
      "source": [
        "# Evaluating cost function\n",
        "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 0);\n",
        "print(f\"Cost: {J:0.2f}\")\n",
        "\n",
        "# Evaluating cost function with regularization\n",
        "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
        "print(f\"Cost (with regularization): {J:0.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilaeM8yWodYR"
      },
      "source": [
        "Training the algorithm for Learning movie recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "WJO8Jr0UodYR",
        "outputId": "7b5b6e0f-6b40-4cfd-bfa2-5981ee5ae6ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "New user ratings:\n",
            "\n",
            "Rated 5.0 for  Shrek (2001)\n",
            "Rated 5.0 for  Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
            "Rated 2.0 for  Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
            "Rated 5.0 for  Harry Potter and the Chamber of Secrets (2002)\n",
            "Rated 5.0 for  Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
            "Rated 5.0 for  Lord of the Rings: The Return of the King, The (2003)\n",
            "Rated 3.0 for  Eternal Sunshine of the Spotless Mind (2004)\n",
            "Rated 5.0 for  Incredibles, The (2004)\n",
            "Rated 2.0 for  Persuasion (2007)\n",
            "Rated 5.0 for  Toy Story 3 (2010)\n",
            "Rated 3.0 for  Inception (2010)\n",
            "Rated 1.0 for  Louis Theroux: Law & Disorder (2008)\n",
            "Rated 1.0 for  Nothing to Declare (Rien à déclarer) (2010)\n"
          ]
        }
      ],
      "source": [
        "movieList, movieList_df = load_Movie_List_pd()\n",
        "\n",
        "my_ratings = np.zeros(num_movies)          #  Initializing my ratings\n",
        "\n",
        "my_ratings[2700] = 5\n",
        "\n",
        "my_ratings[2609] = 2\n",
        "\n",
        "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
        "my_ratings[246]  = 5   # Shrek (2001)\n",
        "my_ratings[2716] = 3   # Inception\n",
        "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
        "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'Amélie Poulain, Le)\n",
        "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
        "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
        "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
        "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
        "my_ratings[2937] = 1   # Nothing to Declare (Rien à déclarer)\n",
        "my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
        "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
        "\n",
        "print('\\nNew user ratings:\\n')\n",
        "for i in range(len(my_ratings)):\n",
        "    if my_ratings[i] > 0 :\n",
        "        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,\"title\"]}');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61VNVPCpKrN4"
      },
      "source": [
        "Now, let's add these reviews to $Y$ and $R$ and normalize the ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4w2cmE67KrN4"
      },
      "outputs": [],
      "source": [
        "# Reload ratings\n",
        "Y, R = load_ratings_small()\n",
        "\n",
        "# Add new user ratings to Y\n",
        "Y = np.c_[my_ratings, Y]\n",
        "\n",
        "# Add new user indicator matrix to R\n",
        "R = np.c_[(my_ratings != 0).astype(int), R]\n",
        "\n",
        "# Normalize the Dataset\n",
        "Ynorm, Ymean = normalizeRatings(Y, R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_O2zBnIKrN4"
      },
      "source": [
        "Let's prepare to train the model. Initialize the parameters and select the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Nywqw1ivKrN5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "num_movies, num_users = Y.shape\n",
        "num_features = 100\n",
        "\n",
        "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
        "tf.random.set_seed(1234) # for consistent results\n",
        "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
        "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
        "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
        "\n",
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlKx6B80KrN5"
      },
      "source": [
        "Let's now train the collaborative filtering model. This will learn the parameters $\\mathbf{X}$, $\\mathbf{W}$, and $\\mathbf{b}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fMgcquKrKrN5",
        "outputId": "f3906090-5105-4c48-9f30-bb63893be32a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss at iteration 0: 2321191.3\n",
            "Training loss at iteration 20: 136168.7\n",
            "Training loss at iteration 40: 51863.3\n",
            "Training loss at iteration 60: 24598.8\n",
            "Training loss at iteration 80: 13630.4\n",
            "Training loss at iteration 100: 8487.6\n",
            "Training loss at iteration 120: 5807.7\n",
            "Training loss at iteration 140: 4311.6\n",
            "Training loss at iteration 160: 3435.2\n",
            "Training loss at iteration 180: 2902.1\n"
          ]
        }
      ],
      "source": [
        "iterations = 200\n",
        "lambda_ = 1\n",
        "for iter in range(iterations):\n",
        "    # Use TensorFlow’s GradientTape\n",
        "    # to record the operations used to compute the cost\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        # Compute the cost (forward pass included in cost)\n",
        "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
        "\n",
        "    # Use the gradient tape to automatically retrieve\n",
        "    # the gradients of the trainable variables with respect to the loss\n",
        "    grads = tape.gradient( cost_value, [X,W,b] )\n",
        "\n",
        "    # Run one step of gradient descent by updating\n",
        "    # the value of the variables to minimize the loss.\n",
        "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
        "\n",
        "    if iter % 20 == 0:\n",
        "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSzUL7eQodYS"
      },
      "source": [
        "### **Recommendations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ns266wKtodYT",
        "outputId": "b487c111-1aad-4089-c644-d1504f64c76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting rating 4.49 for movie My Sassy Girl (Yeopgijeogin geunyeo) (2001)\n",
            "Predicting rating 4.48 for movie Martin Lawrence Live: Runteldat (2002)\n",
            "Predicting rating 4.48 for movie Memento (2000)\n",
            "Predicting rating 4.47 for movie Delirium (2014)\n",
            "Predicting rating 4.47 for movie Laggies (2014)\n",
            "Predicting rating 4.47 for movie One I Love, The (2014)\n",
            "Predicting rating 4.46 for movie Particle Fever (2013)\n",
            "Predicting rating 4.45 for movie Eichmann (2007)\n",
            "Predicting rating 4.45 for movie Battle Royale 2: Requiem (Batoru rowaiaru II: Chinkonka) (2003)\n",
            "Predicting rating 4.45 for movie Into the Abyss (2011)\n",
            "\n",
            "\n",
            "Original vs Predicted ratings:\n",
            "\n",
            "Original 5.0, Predicted 4.90 for Shrek (2001)\n",
            "Original 5.0, Predicted 4.84 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
            "Original 2.0, Predicted 2.13 for Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
            "Original 5.0, Predicted 4.88 for Harry Potter and the Chamber of Secrets (2002)\n",
            "Original 5.0, Predicted 4.87 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
            "Original 5.0, Predicted 4.89 for Lord of the Rings: The Return of the King, The (2003)\n",
            "Original 3.0, Predicted 3.00 for Eternal Sunshine of the Spotless Mind (2004)\n",
            "Original 5.0, Predicted 4.90 for Incredibles, The (2004)\n",
            "Original 2.0, Predicted 2.11 for Persuasion (2007)\n",
            "Original 5.0, Predicted 4.80 for Toy Story 3 (2010)\n",
            "Original 3.0, Predicted 3.00 for Inception (2010)\n",
            "Original 1.0, Predicted 1.41 for Louis Theroux: Law & Disorder (2008)\n",
            "Original 1.0, Predicted 1.26 for Nothing to Declare (Rien à déclarer) (2010)\n"
          ]
        }
      ],
      "source": [
        "# Make a prediction using trained weights and biases\n",
        "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
        "\n",
        "#restore the mean\n",
        "pm = p + Ymean\n",
        "\n",
        "my_predictions = pm[:,0]\n",
        "\n",
        "# sort predictions\n",
        "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
        "\n",
        "for i in range(17):\n",
        "    j = ix[i]\n",
        "    if j not in my_rated:\n",
        "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
        "\n",
        "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
        "for i in range(len(my_ratings)):\n",
        "    if my_ratings[i] > 0:\n",
        "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
